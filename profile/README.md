<div align="center">
<p align="center" style="width: 100%;">
    <img src="./assets/vlm-black.svg" alt="VLM Run Logo" width="80" style="margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;"><br>
</p>
<h2>VLM Run</h2>
  The Unified Gateway for Visual AI
<p align="center"><a href="https://docs.vlm.run"><b>Website</b></a> | <a href="https://app.vlm.run/"><b>Platform</b></a> | <a href="https://docs.vlm.run/"><b>API Docs</b></a> | <a href="https://docs.vlm.run/blog"><b>Blog</b></a>
</p>
<p align="center">
<a href="https://discord.gg/AMApC2UzVY"><img alt="Discord" src="https://img.shields.io/badge/discord-chat-purple?color=%235765F2&label=discord&logo=discord"></a>
<a href="https://twitter.com/vlmrun"><img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/vlmrun.svg?style=social&logo=twitter"></a>
</p>
</div>

AtÂ [VLM Run](https://vlm.run), we're building theÂ Unified Gateway for Visual AIâ€”an end-to-end platform that enables enterprises to seamlessly process and extract value from unstructured visual data. Our inference APIs allow businesses to harness the power of modern Vision-Language Models (VLMs) to accurately extract structured data (JSON) from diverse visual sources like images, videos and documents, acting as ETL for any visual content.

#### ðŸ”—  Quick Links

* ðŸ’¬ Send us an email at [support@vlm.run](mailto:support@vlm.run) or join our [Discord](https://discord.gg/4jgyECY4rq) for help.
* ðŸ“£ Follow us on [Twitter](https://x.com/vlmrun), and [LinkedIn](https://www.linkedin.com/company/vlm-run) to keep up-to-date on our products.
